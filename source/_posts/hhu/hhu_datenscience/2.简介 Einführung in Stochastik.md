---
title: Daten_Science æ€»ç»“-2
date: 2022-08-12 22:44:45
categories : 
- hhu 
- Daten_Science
tags:
password: cocovv
---

# EinfÃ¼hrung in Stochastik

Man kann Stochastik als Oberbegriff fÃ¼r Wahrscheinlichkeitstheorie und Statistik auffassen. Die Statistik beschÃ¤ftigt sich mit stochastischen Modellen, die anhand von Beobachtungen entwickelt werden, und macht Schlussfolgerungen. Die Wahrscheinlichkeitstheorie beschÃ¤ftigt sich mit der Untersuchung von Modellen und der Theorie dahinter.

```
éšæœºä¸»ä¹‰å¯ä»¥è¢«çœ‹ä½œæ˜¯æ¦‚ç‡è®ºå’Œç»Ÿè®¡å­¦çš„ä¸€ä¸ªé€šç”¨æœ¯è¯­ã€‚ç»Ÿè®¡å­¦å¤„ç†çš„æ˜¯åœ¨è§‚å¯ŸåŸºç¡€ä¸Šå»ºç«‹çš„éšæœºæ¨¡å‹ï¼Œå¹¶ä½œå‡ºç»“è®ºã€‚æ¦‚ç‡è®ºæ¶‰åŠå¯¹æ¨¡å‹åŠå…¶èƒŒåç†è®ºçš„ç ”ç©¶ã€‚
```

Wie immer in der Informatik ist ein wesentliches Ziel, mit einem Modell einen Ausschnitt der RealitÃ¤t zu modellieren, d.h. von diesem Ausschnitt zu abstrahieren und mit dem Modell ein StÃ¼ck der RealitÃ¤t vorherzusagen und das Modell an der RealitÃ¤t zu prÃ¼fen.

```
å¦‚åŒè®¡ç®—æœºç§‘å­¦ä¸€æ ·ï¼Œä¸€ä¸ªåŸºæœ¬çš„ç›®æ ‡æ˜¯ç”¨ä¸€ä¸ªæ¨¡å‹æ¥æ¨¡æ‹Ÿç°å®çš„æŸä¸€éƒ¨åˆ†ï¼Œå³ä»è¿™ä¸€éƒ¨åˆ†ä¸­æŠ½è±¡å‡ºæ¥ï¼Œç”¨æ¨¡å‹æ¥é¢„æµ‹ç°å®çš„æŸä¸€éƒ¨åˆ†ï¼Œå¹¶æ ¹æ®ç°å®æ¥æµ‹è¯•æ¨¡å‹ã€‚
```

Wir kennen bereits logische Modelle der RealitÃ¤t: Wenn es regnet, wird der Rasen nass. Wenn ich hungrig bin, und dann viel esse, bin ich danach nicht mehr hungrig.
Statistische Modelle erweitern diese Alles-oder-nichts-Logik nun um verschiedene Grade von PlausibilitÃ¤t: wenn der Rasen nass ist, ist es plausible, anzunehmen, dass es vor kurzem regnete. Es ist ebenso plausibel, anzunehmen, dass jemand den Rasen gewÃ¤ssert hat mit einem Gartenschlauch. Was wir plausibler finden, hÃ¤ngt davon ab, was wir sonst Ã¼ber die RealitÃ¤t wissen. Durch lÃ¤ngere Beobachtung des Rasens kÃ¶nnen wir feststellen, welche GrÃ¼nde wie oft zu einem nassen Rasen fÃ¼hren, und daran unser Modell schÃ¤rfen.

```
æˆ‘ä»¬å·²ç»çŸ¥é“ç°å®çš„é€»è¾‘æ¨¡å‹ï¼šä¸‹é›¨çš„æ—¶å€™ï¼Œè‰åªä¼šè¢«æ‰“æ¹¿ã€‚å¦‚æœæˆ‘å¾ˆé¥¿ï¼Œç„¶ååƒäº†å¾ˆå¤šï¼Œä¹‹åå°±ä¸å†é¥¿äº†ã€‚
ç°åœ¨ï¼Œç»Ÿè®¡æ¨¡å‹ä»¥ä¸åŒç¨‹åº¦çš„å¯ä¿¡åº¦æ¥æ‰©å±•è¿™ç§å…¨æœ‰æˆ–å…¨æ— çš„é€»è¾‘ï¼šå¦‚æœè‰åªæ˜¯æ¹¿çš„ï¼Œé‚£ä¹ˆå‡è®¾æœ€è¿‘ä¸‹è¿‡é›¨æ˜¯å¯ä¿¡çš„ã€‚å‡è®¾æœ‰äººç”¨èŠ±å›­æ°´ç®¡æµ‡çŒè‰åªï¼Œä¹Ÿæ˜¯åŒæ ·åˆç†çš„ã€‚æˆ‘ä»¬è®¤ä¸ºä»€ä¹ˆæ›´åˆç†ï¼Œå–å†³äºæˆ‘ä»¬å¯¹ç°å®çš„å…¶ä»–äº†è§£ã€‚é€šè¿‡å¯¹è‰åªè¿›è¡Œè¾ƒé•¿æ—¶é—´çš„è§‚å¯Ÿï¼Œæˆ‘ä»¬å¯ä»¥ç¡®å®šå“ªäº›åŸå› ä¼šå¯¼è‡´è‰åªæ½®æ¹¿ä»¥åŠæ½®æ¹¿çš„é¢‘ç‡ï¼Œå¹¶ä»¥æ­¤æ¥å®Œå–„æˆ‘ä»¬çš„æ¨¡å‹ã€‚
```

Um mit PlausibilitÃ¤t genau so rechnen zu kÃ¶nnen wie mit Boolescher Logik, und schlieÃŸlich auch im Computer zu implementieren, mÃ¼ssen wir die PlausibilitÃ¤tswerte mit Zahlen versehen. Eine geeignete Abstraktion sind reelle Zahlen, denn reelle Zahlen sind der einzige archimedisch angeordnete vollstÃ¤ndige KÃ¶rper, der die rationalen Zahlen enthÃ¤lt (und die darin enthaltene Unteralgebra der berechenbaren reellen Zahlen hat uns schon viele gute Dienste geleistet).

```
ä¸ºäº†èƒ½å¤Ÿä»¥ä¸å¸ƒå°”é€»è¾‘å®Œå…¨ç›¸åŒçš„æ–¹å¼è¿›è¡Œå¯ä¿¡åº¦è®¡ç®—ï¼Œå¹¶æœ€ç»ˆåœ¨è®¡ç®—æœºä¸­å®ç°å®ƒï¼Œæˆ‘ä»¬å¿…é¡»ç”¨æ•°å­—æä¾›å¯ä¿¡åº¦å€¼ã€‚ä¸€ä¸ªåˆé€‚çš„æŠ½è±¡æ˜¯å®æ•°ï¼Œå› ä¸ºå®æ•°æ˜¯å”¯ä¸€åŒ…å«æœ‰ç†æ•°çš„é˜¿åŸºç±³å¾·å®Œå…¨ä½“ï¼ˆå…¶ä¸­åŒ…å«çš„å¯è®¡ç®—å®æ•°çš„å­ä»£æ•°å·²ç»ä¸ºæˆ‘ä»¬æœåŠ¡äº†ï¼‰ã€‚
```

Wir wÃ¼nschen uns auÃŸerdem, dass PlausibilitÃ¤tslogik mit der klassischen Logik kompatibel ist, d.h. logisch Ã¤quivalente Aussagen sollten gleich plausibel sein und verschiedene Wege, um die PlausibilitÃ¤t einer Aussage zu bestimmen, sollten zum gleichen Ergebnis kommen (Konsistenz).
Um das in Mathematik zu formulieren, nennen wir nun eine endliche Menge von Aussagen, deren PlausibilitÃ¤t wir bewerten wollen, $X$ und die Zuordnung der PlausibilitÃ¤t ist eine Abbildung $p \colon X \to \mathbb{R}$.

```
æˆ‘ä»¬è¿˜å¸Œæœ›å¯ä¿¡æ€§é€»è¾‘èƒ½ä¸ç»å…¸é€»è¾‘å…¼å®¹ï¼Œå³åœ¨é€»è¾‘ä¸Š
ç›¸ç­‰çš„é™ˆè¿°åº”è¯¥æ˜¯åŒæ ·å¯ä¿¡çš„ï¼Œè€Œç¡®å®šé™ˆè¿°å¯ä¿¡åº¦çš„ä¸åŒæ–¹æ³•
åº”è¯¥å¾—å‡ºç›¸åŒçš„ç»“æœï¼ˆä¸€è‡´æ€§ï¼‰ã€‚ä¸ºäº†åœ¨æ•°å­¦ä¸­è¡¨è¿°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬ç§°
æˆ‘ä»¬ç°åœ¨ç§°ä¸€ä¸ªæœ‰é™çš„é™ˆè¿°é›†ï¼Œæˆ‘ä»¬è¦å¯¹å…¶å¯ä¿¡åº¦è¿›è¡Œè¯„ä¼°ğ‘‹ï¼Œå¹¶ä¸”å¯¹å…¶è¿›è¡Œåˆ†é…ã€‚
å¯ä¿¡æ€§æ˜¯ä¸€ä¸ªæ˜ å°„ âˆ¶ ğ‘ âˆ¶ ğ‘‹ â†’ â„ ã€‚
```

Wenn man diese Forderungen prÃ¤zisiert, kann man das Cox-Jaynes-Theorem beweisen, dass besagt, dass es eine mathematische Abbildung $cj$ von den reellen Zahlen in das geschlossene Intervall $[0,1]$ gibt, die PlausibilitÃ¤ten auf "Wahrscheinlichkeiten" abbildet, sodass (fast) alle Regeln der klassischen Wahrscheinlichkeitstheorie erfÃ¼llt sind. So erfÃ¼llt $P := cj \circ p \colon X \to [0,1]$ die Regeln
1. $P(WAHR) = 1$ und $P(FALSCH) = 0$.
1. Wenn $A_1,\dots,A_n$ eine endliche Menge paarweise unabhÃ¤ngiger Aussagen sind, dann gilt endliche AdditivitÃ¤t:
$ P\left( \bigcup_{i=1} A_i \right) = \sum_{i=1}^n P(A_i) $

```
å¦‚æœæ˜ç¡®äº†è¿™äº›è¦æ±‚ï¼Œå°±å¯ä»¥è¯æ˜è€ƒå…‹æ–¯-æ°æ©æ–¯å®šç†ï¼Œå³å­˜åœ¨ä¸€ä¸ªä»å®æ•°åˆ°å°é—­åŒºé—´[0ï¼Œ1]çš„æ•°å­¦æ˜ å°„ğ‘ğ‘—ï¼Œå°†å¯ä¿¡åº¦æ˜ å°„ä¸º "æ¦‚ç‡"ï¼Œä»è€Œæ»¡è¶³å¤å…¸æ¦‚ç‡è®ºçš„ï¼ˆå‡ ä¹ï¼‰æ‰€æœ‰è§„åˆ™ã€‚å› æ­¤ğ‘ƒâˆ¶= ğ‘ğ‘— âˆ˜ ğ‘ âˆ¶ ğ‘‹ â†’ [0, 1] æ»¡è¶³è§„åˆ™
```

Wir werden uns nun der modernen Fassung des Wahrscheinlichkeitsbegriffs nÃ¤hern.

æˆ‘ä»¬ç°åœ¨å°†æ¥è¿‘æ¦‚ç‡æ¦‚å¿µçš„ç°ä»£ç‰ˆæœ¬ã€‚

## Das MaÃŸproblem

Bei einem WÃ¼rfel oder einer MÃ¼nze ist relativ klar, wie wir die Wahrscheinlichkeit modellieren und wie wir ein statistisches Modell aufstellen kÃ¶nnen, das wir auch implementieren kÃ¶nnen. In der Theorie stellt sich aber schnell die Frage, wie es z.B. mit einem unendlich oft wiederholten Experiment aussieht. Das ist keine rein theoretische Frage, denn wir sind an der Asymptotik interessiert, also wie sich ein hinreichend oft wiederholtes Experiment nÃ¤herungsweise verhÃ¤lt.

```
2.1 æµ‹é‡é—®é¢˜
é€šè¿‡ä¸€ä¸ªéª°å­æˆ–ç¡¬å¸ï¼Œæˆ‘ä»¬å¦‚ä½•å»ºç«‹æ¦‚ç‡æ¨¡å‹ï¼Œä»¥åŠå¦‚ä½•å»ºç«‹ä¸€ä¸ªæˆ‘ä»¬ä¹Ÿèƒ½å®ç°çš„ç»Ÿè®¡æ¨¡å‹ï¼Œæ˜¯æ¯”è¾ƒæ¸…æ¥šçš„ã€‚ç„¶è€Œï¼Œåœ¨ç†è®ºä¸Šï¼Œå¾ˆå¿«å°±ä¼šå‡ºç°è¿™æ ·çš„é—®é¢˜ï¼šä¾‹å¦‚ï¼Œä¸€ä¸ªé‡å¤äº†æ— é™æ¬¡çš„å®éªŒä¼šå‘ç”Ÿä»€ä¹ˆã€‚è¿™ä¸æ˜¯ä¸€ä¸ªçº¯ç²¹çš„ç†è®ºé—®é¢˜ï¼Œå› ä¸ºæˆ‘ä»¬å¯¹æ¸è¿›æ³•æ„Ÿå…´è¶£ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€ä¸ªè¶³å¤Ÿé¢‘ç¹çš„é‡å¤å®éªŒæ˜¯å¦‚ä½•è¿‘ä¼¼è¡¨ç°çš„ã€‚
```

Unendlich oft wiederholte MÃ¼nzwÃ¼rfe kÃ¶nnen wir wie eine unendliche Folge von $0$en und $1$en notieren, und bei nÃ¤herer Betrachtung liefert uns das auch eine Darstellung fÃ¼r reelle Zahlen im Einheitsintervall $[0,1]$, die sich im Rechner eben so gut implementieren lÃ¤sst, wie der Rechner eine Turingmaschine ist (in der RealitÃ¤t ist das Band endlich, aber wir kÃ¶nnen es ja immer wieder verlÃ¤ngern - bzw. der Speicher unserer Rechner ist beschrÃ¤nkt aber nicht auf einen festen Wert).

```
æˆ‘ä»¬å¯ä»¥åƒä¸€ä¸ªæ— é™çš„0å’Œ1çš„åºåˆ—ä¸€æ ·è®°ä¸‹æ— é™æ¬¡é‡å¤çš„æŠ›ç¡¬å¸ï¼Œä»”ç»†è§‚å¯Ÿï¼Œè¿™ä¹Ÿä¸ºæˆ‘ä»¬æä¾›äº†å•ä½åŒºé—´[0ï¼Œ1]ä¸­å®æ•°çš„è¡¨ç¤ºæ–¹æ³•ï¼Œå®ƒå¯ä»¥åœ¨è®¡ç®—æœºä¸­å®ç°ï¼Œå°±åƒè®¡ç®—æœºæ˜¯ä¸€å°å›¾çµæœºä¸€æ ·ï¼ˆå®é™…ä¸Šï¼Œç£å¸¦æ˜¯æœ‰é™çš„ï¼Œä½†æˆ‘ä»¬æ€»æ˜¯å¯ä»¥æ‰©å±•å®ƒ--æˆ–è€…è¯´æˆ‘ä»¬è®¡ç®—æœºçš„å†…å­˜æ˜¯æœ‰é™çš„ï¼Œä½†ä¸æ˜¯ä¸€ä¸ªå›ºå®šå€¼ï¼‰ã€‚
```

Wir mÃ¶chten nun gerne jedem Ergebnis (jedem Versuchsausgang beim unendlich oft wiederholten MÃ¼nzwurf) eine Wahrscheinlichkeit zuordnen, sodass $P(\Omega)=1$ ist, wobei $\Omega = \{0,1\}^{\mathbb{N}}$ der Ergebnisraum ist.
AuÃŸerdem soll fÃ¼r paarweise disjunkte Teilmengen $A_i \subset \Omega$ die endliche AdditivitÃ¤t gelten:

æˆ‘ä»¬ç°åœ¨æƒ³ç»™æ¯ä¸ªç»“æœï¼ˆæ— é™é‡å¤æŠ›ç¡¬å¸çš„æ¯ä¸ªè¯•éªŒç»“æœï¼‰åˆ†é…ä¸€ä¸ªæ¦‚ç‡ï¼Œä½¿ğ‘ƒï¼ˆÎ©ï¼‰=1ï¼Œå…¶ä¸­Î©={0, 1}â„•æ˜¯ç»“æœç©ºé—´ã€‚æ­¤å¤–ï¼Œå¯¹äºæˆå¯¹ä¸ç›¸äº¤çš„å­é›†ğ´ğ‘– âŠ‚Î©ï¼Œè®©æœ‰é™å¯åŠ æ€§æˆç«‹ã€‚

$P\left( \bigcup_{i=1}^n A_i \right) = \sum_{i=1}^n P(A_i)$

Eine weitere natÃ¼rliche Forderung ist die Flip-Invarianz, also dass es fÃ¼r die Wahrscheinlichkeit keinen Unterschied macht, ob ich den $n$-ten MÃ¼nzwurf (das $n$-te bit) genau umdrehe. Man kann das formalisieren Ã¼ber einen Operator $F_n \colon \Omega \to \Omega$ mit

å¦ä¸€ä¸ªè‡ªç„¶è¦æ±‚æ˜¯ç¿»è½¬ä¸å˜æ€§ï¼Œå³æˆ‘æ˜¯å¦å‡†ç¡®ç¿»è½¬ç¬¬ğ‘›ç¡¬å¸ï¼ˆç¬¬ğ‘›ä½ï¼‰å¯¹æ¦‚ç‡æ²¡æœ‰å½±å“ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ä¸ªç®—å­ğ¹ğ‘› âˆ¶ Ï‰ â†’ Ï‰æ¥æ­£å¼è¯´æ˜è¿™ä¸€ç‚¹ã€‚

$F_n(\omega_1,\dots,\omega_{n-1},\omega_n,\omega_{n+1},\dots) =
     (\omega_1,\dots,\omega_{n-1},1-\omega_n,\omega_{n+1},\dots)$
     
Dann erwarten wir fÃ¼r jede Teilmenge $A \subset \Omega$ dass $P(F_n A) = P(A)$ gilt.

```
é‚£ä¹ˆå¯¹äºæ¯ä¸€ä¸ªå­é›†ğ´âŠ‚Î©ï¼Œæˆ‘ä»¬å¸Œæœ›ğ‘ƒï¼ˆğ¹ğ‘›ğ´ï¼‰=ğ‘ƒï¼ˆğ´ï¼‰æˆç«‹ã€‚
```

Im Jahr 1923 hat Banach mit Hilfe des Auswahlaxioms bewiesen, dass es zwar mÃ¶glich ist, nicht-konstruktiv so eine Wahrscheinlichkeit $P$ zu definieren, dass es aber nicht eindeutig mÃ¶glich ist!

```
1923å¹´ï¼Œå·´çº³èµ«ç”¨é€‰æ‹©å…¬ç†è¯æ˜ï¼Œå°½ç®¡æœ‰å¯èƒ½éç»“æ„æ€§åœ°å®šä¹‰è¿™æ ·ä¸€ä¸ªæ¦‚ç‡ğ‘ƒï¼Œä½†å®ƒä¸æ˜¯å”¯ä¸€å¯èƒ½çš„!
```

Wenn wir eine unserer Forderungen verschÃ¤rfen, nÃ¤mlich von der endlichen AdditivitÃ¤t zur $\sigma$-AdditivitÃ¤t (man sagt Sigma-AdditivitÃ¤t oder abzÃ¤hlbare AdditivitÃ¤t), hat schon 1905 Vitali bewiesen, dass es Ã¼berhaupt keine solche Abbildung $P$ gibt, es also unmÃ¶glich ist, unendlichen MÃ¼nzwÃ¼rfen so Wahrscheinlichkeiten zuzuordnen. Woran liegt das, und was soll das mit der $\sigma$-AdditivitÃ¤t?

```
å¦‚æœæˆ‘ä»¬æ”¶ç´§æˆ‘ä»¬çš„ä¸€ä¸ªä¸»å¼ ï¼Œå³ä»æœ‰é™å¯åŠ æ€§åˆ°ğœå¯åŠ æ€§ï¼ˆä¸€è¯´æ˜¯Ïƒå¯åŠ æ€§æˆ–å¯æ•°å¯åŠ æ€§ï¼‰ï¼Œç»´å¡”åˆ©åœ¨1905å¹´å·²ç»è¯æ˜æ ¹æœ¬ä¸å­˜åœ¨è¿™æ ·çš„æ˜ å°„ğ‘ƒï¼Œæ‰€ä»¥ä¸å¯èƒ½åƒè¿™æ ·ç»™æ— é™çš„æŠ›ç¡¬å¸åˆ†é…æ¦‚ç‡ã€‚è¿™æ˜¯ä»€ä¹ˆåŸå› å‘¢ï¼Ÿ"ğœåŠ æ€§ "æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ
```
## Offene Mengen messen

Eine sehr praktische Definition fÃ¼r jede Menge $X$ auf der es einen Abstandsbegriff gibt (genauer: $X$ ein metrischer Raum) ist diese:
Eine Menge $U \subset X$ heiÃŸt *offen* wenn es um jeden Punkt $u \in U$ einen Abstand $\epsilon > 0$ gibt, sodass alle Punkte $x \in X$ mit Abstand $d(x,u) < \epsilon$ bereits gÃ¤nzlich in $U$ liegen, also $x \in U$.

```
2.2 æµ‹é‡å¼€æ”¾é›†
å¯¹äºä»»ä½•å­˜åœ¨è·ç¦»é¡¹çš„é›†åˆğ‘‹ï¼ˆæ›´ç¡®åˆ‡åœ°è¯´ï¼Œğ‘‹æ˜¯ä¸€ä¸ªå…¬åˆ¶ç©ºé—´ï¼‰ï¼Œä¸€ä¸ªéå¸¸æ–¹ä¾¿çš„å®šä¹‰æ˜¯è¿™æ ·çš„ã€‚å¦‚æœåœ¨æ¯ä¸€ä¸ªç‚¹ğ‘¢âˆˆğ‘ˆ å‘¨å›´éƒ½æœ‰ä¸€ä¸ªè·ç¦»ğœ–>0ï¼Œä½¿å¾—æ‰€æœ‰è·ç¦»ğ‘‘(ğ‘¥ï¼Œğ‘¢)<ğœ–çš„ç‚¹ğ‘¥âˆˆğ‘‹å·²ç»å®Œå…¨ä½äºğ‘ˆï¼Œå³ğ‘¥âˆˆğ‘ˆï¼Œé‚£ä¹ˆè¿™ä¸ªé›†åˆğ‘ˆ ç§°ä¸ºå¼€æ”¾ã€‚
```

Man kann nun zeigen, dass die klassische $\epsilon$-$\delta$-Definition von Stetigkeit Ã¤quivalent ist zu: $f \colon X \to Y$ heiÃŸt *stetig* wenn die Urbilder offener Mengen $U \subset Y$ auch offene Mengen $f^{-1}(U) \subset X$ sind.

Wenn wir auf den Zahlen im Intervall $[0,1]$ eine Gleichverteilung definieren wollen (so wie im unendlichen MÃ¼nzwurf-Beispiel), oder auch gleich auf allen reellen Zahlen, dann wissen wir eigentlich schon ganz genau, wie wir mit Intervallen verfahren wollen: fÃ¼r ein Intervall $[a,b]$ soll die Wahrscheinlichkeit / das MaÃŸ eben $b-a$ sein.

```
æˆ‘ä»¬ç°åœ¨å¯ä»¥è¯æ˜ï¼Œç»å…¸çš„ğœ–-ğ›¿å®šä¹‰çš„è¿ç»­æ€§ç­‰åŒäºï¼šå¦‚æœå¼€æ”¾é›†ğ‘ˆâŠ‚ğ‘Œçš„åŸå§‹å›¾åƒä¹Ÿæ˜¯å¼€æ”¾é›†ğ‘“-1ï¼ˆğ‘ˆï¼‰âŠ‚ğ‘‹ï¼Œåˆ™ğ‘Œæ˜¯è¿ç»­çš„ã€‚
å¦‚æœæˆ‘ä»¬æƒ³åœ¨åŒºé—´[0, 1]ä¸­çš„æ•°å­—ä¸Šå®šä¹‰ä¸€ä¸ªå‡åŒ€åˆ†å¸ƒï¼ˆå¦‚æ— é™æ·ç¡¬å¸çš„ä¾‹å­ï¼‰ï¼Œç”šè‡³åœ¨æ‰€æœ‰å®æ•°ä¸Šå®šä¹‰ä¸€ä¸ªå‡åŒ€åˆ†å¸ƒï¼Œé‚£ä¹ˆæˆ‘ä»¬å®é™…ä¸Šå·²ç»æ¸…æ¥šåœ°çŸ¥é“æˆ‘ä»¬è¦å¦‚ä½•å¤„ç†åŒºé—´ï¼šå¯¹äºä¸€ä¸ªåŒºé—´[ğ‘, ğ‘]ï¼Œæ¦‚ç‡/åº¦é‡åº”è¯¥æ˜¯ğ‘- ğ‘ã€‚
```
Da sich jede offene Menge in $\mathbb{R}$ als abzÃ¤hlbare Vereinigung von Intervallen schreiben lÃ¤sst, wissen wir also, wie den offenen Mengen ein MaÃŸ zugeordnet werden kann: als abzÃ¤hlbare Summe Ã¼ber die LÃ¤ngen eben dieser Intervalle. Es stellt sich heraus, dass man so eine Gleichverteilung definieren kann, nur eben nicht fÃ¼r beliebige Teilmengen von $\mathbb{R}$ oder $[0,1]$ einen Wahrscheinlichkeitswert bestimmen. Man sagt, es gibt *nicht-messbare Mengen*.

Aus dieser Beobachtung leiten wir nun die Forderung ab, dass unsere Wahrscheinlichkeit $P$ nicht nur endlich additiv sein soll, sondern $\sigma$-additiv. Nach dem Satz von Vitali akzeptieren wir, dass nicht jede Teilmenge von $\mathbb{R}$ messbar ist und begnÃ¼gen uns damit, eine Teilalgebra von $\mathcal{P}(\mathbb{R})$ auszuzeichen, die *meÃŸbaren Mengen*.

```
ç”±äºâ„ä¸­çš„æ¯ä¸ªå¼€æ”¾é›†éƒ½å¯ä»¥å†™æˆä¸€ä¸ªå¯æ•°çš„åŒºé—´è”ç›Ÿï¼Œæˆ‘ä»¬çŸ¥é“å¦‚ä½•ç»™å¼€æ”¾é›†åˆ†é…ä¸€ä¸ªåº¦é‡ï¼šä½œä¸ºè¿™äº›åŒºé—´é•¿åº¦çš„å¯æ•°å’Œã€‚äº‹å®è¯æ˜ï¼Œäººä»¬å¯ä»¥ç”¨è¿™ç§æ–¹å¼å®šä¹‰å‡åŒ€åˆ†å¸ƒï¼Œåªæ˜¯ä¸èƒ½ç¡®å®šâ„æˆ–[0ï¼Œ1]çš„ä»»æ„å­é›†çš„æ¦‚ç‡å€¼ã€‚æˆ‘ä»¬è¯´ï¼Œå­˜åœ¨ç€ä¸å¯æµ‹é‡çš„é›†åˆã€‚
ä»è¿™ä¸ªè§‚å¯Ÿä¸­ï¼Œæˆ‘ä»¬ç°åœ¨æ¨å¯¼å‡ºæˆ‘ä»¬çš„æ¦‚ç‡ğ‘ƒä¸ä»…åº”è¯¥æ˜¯æœ‰é™åŠ æ€§çš„ï¼Œè€Œä¸”æ˜¯ğœåŠ æ€§çš„è¦æ±‚ã€‚æ ¹æ®ç»´å¡”åˆ©å®šç†ï¼Œæˆ‘ä»¬æ¥å—å¹¶éæ¯ä¸€ä¸ªâ„çš„å­é›†éƒ½æ˜¯å¯æµ‹çš„ï¼Œå¹¶ä¸”æ»¡è¶³äºç­¾å‡ºğ’«(â„)çš„ä¸€ä¸ªå­ä»£æ•°ï¼Œå³å¯æµ‹é›†ã€‚
```

## Formalismus å½¢å¼ä¸»ä¹‰

:::{admonition} Definition
Sei $\Omega$ eine Menge. Dann heiÃŸt ein Mengensystem $\mathcal{F} \subset \mathcal{P}(\Omega)$ eine *$\sigma$-Algebra*, wenn
1. $\Omega \in \mathcal{F}$ "WAHR ist meÃŸbar"
1. $A \in \mathcal{F} \implies A^c := \Omega - A \in \mathcal{F}$ "logisches NICHT"
1. $A_1,\dots \in \mathcal{F} \implies \bigcup_{i\geq 1} A_i \in \mathcal{F}$ "logisches ODER"

Terminologie: wir nennen die Elemente von $\Omega$ die *Ergebnisse* und die Elemente von $\mathcal{F}$ die meÃŸbaren Teilmengen oder auch *Ereignisse*. Das Paar $(\Omega,\mathcal{F})$ ist ein *Ereignisraum*.
:::

:::{admonition} Beispiel
ein gewÃ¶hnlicher WÃ¼rfel hat Zustandsraum $\Omega = \{1,2,3,4,5,6\}$ und die Potenzmenge $\mathcal{P}(\Omega)$ ist bereits eine $\sigma$-Algebra (es gibt also keine nicht-meÃŸbaren Mengen - das klappt fÃ¼r endliches $\Omega$ immer). Ein einzelner WÃ¼rfelwurf liefert ein Ergebnis, die Augenzahl. Die Aussage "die WÃ¼rfelaugen sind eine gerade Zahl" ist eine logische Aussage, die zu dem Ereignis $\{2,4,6\} \subset \Omega$ korrespondiert. In sehr vielen FÃ¤llen sind wir (notgedrungen) nicht an konkreten Ergebnissen interessiert, sondern an bestimmten Ereignissen.

ä¾‹å­
æ™®é€šæ¨¡å…·çš„çŠ¶æ€ç©ºé—´Î©={1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œ5ï¼Œ6}ï¼Œå¹‚é›†ğ’«(Î©)å·²ç»æ˜¯ä¸€ä¸ªğœä»£æ•°ï¼ˆæ‰€ä»¥æ²¡æœ‰ä¸å¯æµ‹é‡çš„é›†åˆ--è¿™å¯¹æœ‰é™çš„Î©æ€»æ˜¯æœ‰æ•ˆçš„ï¼‰ã€‚æ·ä¸€æ¬¡éª°å­ä¼šäº§ç”Ÿä¸€ä¸ªç»“æœï¼Œå³çœ¼ç›çš„æ•°é‡ã€‚"éª°å­çš„çœ¼ç›æ˜¯å¶æ•° "è¿™ä¸ªè¯­å¥æ˜¯å¯¹åº”äºäº‹ä»¶{2ã€4ã€6}âŠ‚Î©çš„é€»è¾‘è¯­å¥ã€‚åœ¨å¾ˆå¤šæƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ï¼ˆå‡ºäºå¿…è¦ï¼‰å¯¹å…·ä½“ç»“æœä¸æ„Ÿå…´è¶£ï¼Œè€Œæ˜¯å¯¹æŸäº›äº‹ä»¶æ„Ÿå…´è¶£ã€‚
:::

:::{admonition} Definition
Eine Funktion $P \colon \mathcal{F} \to [0,1]$ von einer $\sigma$-Algebra auf einer Menge $\Omega$ in das Einheitsintervall heiÃŸt *WahrscheinlichkeitsmaÃŸ* wenn
1. $P(\Omega) = 1$ (Normierung) und
1. FÃ¼r paarweise disjunkte Ereignisse $A_i \in \mathcal{F}$ gilt $\sigma$-AdditivitÃ¤t:
$P \left( \bigcup_{i\geq 1} A_i \right) = \sum_{i\geq 1} P(A_i)$

Das Tripel $(\Omega, \mathcal{F}, P)$ heiÃŸt *Wahrscheinlichkeitsraum*.
:::

:::{admonition} Beispiel
Auf einer endlichen Menge $\Omega$ von KardinalitÃ¤t $N := |\Omega|$ (also Anzahl der Elemente $N$) ist mit $\mathcal{F} := \mathcal{P}(\Omega)$ und $P(A) := |A| / N$ ein WahrscheinlichkeitsmaÃŸ definiert, dass wir *Gleichverteilung* nennen.

ä¾‹å­
åœ¨ä¸€ä¸ªæœ‰é™é›†Î©çš„cardinality âˆ¶= |Î©|ï¼ˆå³å…ƒç´ æ•°ğ‘ï¼‰ä¸Šï¼Œâ„± âˆ¶= ğ’«ï¼ˆÎ©ï¼‰ï¼Œğ‘ƒï¼ˆğ´ï¼‰âˆ¶= |ğ´|/ğ‘ï¼Œå®šä¹‰ä¸€ä¸ªæ¦‚ç‡åº¦é‡ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºç»Ÿä¸€åˆ†å¸ƒã€‚
:::

:::{admonition} Beispiel
FÃ¼r einen beliebigen Ereignisraum $(\Omega,\mathcal{F})$ und ein festes Element $\xi \in \Omega$ ist mit

$\delta_\xi := A \mapsto \begin{cases} 1 & \xi \in A,\\ 0 & \text{sonst} \end{cases}$

ein WahrscheinlichkeitsmaÃŸ definiert, das *Dirac-MaÃŸ* mit Einheitsmasse am Punkt $\xi$.
:::

:::{admonition} Proposition
**Rechenregeln** fÃ¼r WahrscheinlichkeitsmaÃŸe:
FÃ¼r jeden Wahrscheinlichkeitsraum $(\Omega,\mathcal{F},P)$ mit $A,B \in \mathcal{F}$ gilt:
1. $P(\emptyset) = 0$
1. Endliche AdditivitÃ¤t: $P(A \cup B) + P(A \cap B) = P(A) + P(B)$
1. Monotonie: $A \subset B \implies P(A) \leq P(B)$
1. $\sigma$-SubadditivitÃ¤t: $P \left( \bigcup_{i\geq 1} A_i \right) \leq \sum_{i\geq 1} P(A_i)$
   (wenn die $A_i \in \mathcal{F}$ nicht notwendig disjunkt sind)
:::

:::{admonition} Beweis
1. $1 = P(\Omega) = P(\emptyset \cup \Omega) = P(\emptyset) + P(\Omega) = P(\emptyset) + 1$
1. $P(A \cup B) = P(A \cup (B - A)) = P(A) + P(B - A)$ und
   $P(B - A) + P(A \cap B) = P((B - A) \cup (A \cap B)) = P(B)$ also
   $P(A \cup B) + P(A \cap B) = P(A) + P(B - A) + P(A \cap B) = P(A) + P(B)$
1. $A \subset B \implies B = A \cup (B - A)$
   $\phantom{A \subset B} \implies P(A) \leq P(A) + P(B - A) = P(A \cup (B - A)) = P(B)$
1. den Leser\*innen als Ãœbung Ã¼berlassen.
:::

:::{admonition} Definition
Eine Funktion $f \colon X\to Y$ zwischen WahrscheinlichkeitsrÃ¤umen $X$ und $Y$ (die $\sigma$-Algebren und WahrscheinlichkeitsmaÃŸe notieren wir nicht mehr extra dazu) heiÃŸt *meÃŸbar* oder auch *Zufallsvariable* wenn fÃ¼r meÃŸbare Mengen $U \subset Y$ die Urbilder $f^{-1}(U) \subset X$ ebenfalls meÃŸbar sind.
å¦‚æœå¯¹äºå¯æµ‹é›†ğ‘ˆâŠ‚ğ‘Œï¼Œå…¶åŸå§‹å›¾åƒğ‘“-1(ğ‘ˆ)âŠ‚ğ‘‹ä¹Ÿæ˜¯å¯æµ‹çš„ï¼Œé‚£ä¹ˆä¸€ä¸ªå‡½æ•°ğ‘“âˆ¶ğ‘‹â†’ğ‘Œï¼ˆæˆ‘ä»¬ä¸å•ç‹¬æ³¨æ„ğœä»£æ•°å’Œæ¦‚ç‡è®¡é‡ï¼‰è¢«ç§°ä¸ºå¯æµ‹æˆ–éšæœºå˜é‡ã€‚
:::

:::{admonition} Beispiel
Wenn wir auf $[0,1]$ die Gleichverteilung definieren, indem wir auf offenen Intervallen die IntervalllÃ¤nge als WahrscheinlichkeitsmaÃŸ festlegen, so ist jede stetige Funktion $f \colon [0,1] \to [0,1]$ auch meÃŸbar.
ä¾‹å­
å¦‚æœæˆ‘ä»¬é€šè¿‡æŒ‡å®šåŒºé—´é•¿åº¦ä½œä¸ºå¼€æ”¾åŒºé—´çš„æ¦‚ç‡åº¦é‡æ¥å®šä¹‰[0, 1]ä¸Šçš„å‡åŒ€åˆ†å¸ƒï¼Œé‚£ä¹ˆæ¯ä¸ªè¿ç»­å‡½æ•°ğ‘“ âˆ¶[0, 1]â†’[0, 1]ä¹Ÿæ˜¯å¯æµ‹çš„ã€‚
:::

Der Begriff Zufallsvariable ist sehr irrefÃ¼hrend: es gibt hier keine Variable und keinen Zufall. WÃ¤hrend der Begriff der meÃŸbaren Abbildung auch auÃŸerhalb der Wahrscheinlichkeitstheorie sinnvoll ist, hat der Begriff der Zufallsvariable aber eine andere typische Verwendung, andere syntaktische Gepflogenheiten. Wir dÃ¼rfen uns diese begriffliche Ãœberladung so vorstellen, wie einen API-Wrapper, der uns zusÃ¤tzlichen syntaktischen Zucker gibt - eine Abbildung, die als Zufallsvariable daher kommt, lÃ¤sst sich wie eine Variable einsetzen, die zufÃ¤llige Werte annimmt. Wir werden diese Perspektive noch stÃ¤rker nutzen und einÃ¼ben.

```
éšæœºå˜é‡è¿™ä¸ªè¯éå¸¸å…·æœ‰è¯¯å¯¼æ€§ï¼šè¿™é‡Œæ²¡æœ‰å˜é‡ï¼Œä¹Ÿæ²¡æœ‰éšæœºæ€§ã€‚è™½ç„¶å¯æµ‹é‡æ˜ å°„ä¸€è¯åœ¨æ¦‚ç‡è®ºä¹‹å¤–æ˜¯æœ‰æ„ä¹‰çš„ï¼Œä½†éšæœºå˜é‡ä¸€è¯å´æœ‰ä¸åŒçš„å…¸å‹ç”¨æ³•ï¼Œä¸åŒçš„å¥æ³•æƒ¯ä¾‹ã€‚æˆ‘ä»¬å¯ä»¥æŠŠè¿™ç§æ¦‚å¿µä¸Šçš„é‡è½½çœ‹ä½œæ˜¯ä¸€ä¸ªAPIåŒ…è£…å™¨ï¼Œå®ƒä¸ºæˆ‘ä»¬æä¾›äº†é¢å¤–çš„è¯­æ³•ç³–--ä¸€ä¸ªä½œä¸ºéšæœºå˜é‡çš„æ˜ å°„å¯ä»¥åƒä¸€ä¸ªæ¥å—éšæœºå€¼çš„å˜é‡ä¸€æ ·ä½¿ç”¨ã€‚æˆ‘ä»¬å°†æ›´å¤šåœ°ä½¿ç”¨å’Œå®è·µè¿™ä¸€è§‚ç‚¹ã€‚
```

Wir wollen uns im Folgenden nicht weiter mit der MaÃŸtheorie beschÃ¤ftigen, die einiges an Aufwand erfordert, um z.B. das allgemeine Lebesgue-Integral zu definieren. Aufgrund der Anwendungen in der Informatik, insbesondere im maschinellen Lernen wollen wir aber eins festhalten: wÃ¤hrend das Riemann-Integral durch Approximation mit FlÃ¤cheninhalten von Rechtecken gebildet wird, bildet man das Lebesgue-Integral durch Approximation der Funktion selbst durch Treppenfunktionen.

```
åœ¨ä¸‹æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¸æƒ³è¿›ä¸€æ­¥å¤„ç†åº¦é‡ç†è®ºï¼Œå› ä¸ºè¿™éœ€è¦ä»˜å‡ºä¸€äº›åŠªåŠ›æ¥å®šä¹‰ï¼Œä¾‹å¦‚ï¼Œä¸€èˆ¬çš„Lebesgueç§¯åˆ†ã€‚ç„¶è€Œï¼Œç”±äºåœ¨è®¡ç®—æœºç§‘å­¦ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨æœºå™¨å­¦ä¹ ä¸­çš„åº”ç”¨ï¼Œæˆ‘ä»¬æƒ³è¯´æ˜ä¸€ç‚¹ï¼šé»æ›¼ç§¯åˆ†æ˜¯é€šè¿‡ç”¨çŸ©å½¢çš„é¢ç§¯å†…å®¹è¿›è¡Œé€¼è¿‘å½¢æˆçš„ï¼Œè€Œå‹’è´æ–¯æ ¼ç§¯åˆ†æ˜¯é€šè¿‡ç”¨é˜¶æ¢¯å‡½æ•°å¯¹å‡½æ•°æœ¬èº«è¿›è¡Œé€¼è¿‘å½¢æˆã€‚
```

:::{admonition} Definition
Eine Treppenfunktion ist eine meÃŸbare Funktion, die nur endlich viele verschiedene Werte annimmt.
æ¢¯å½¢å‡½æ•°æ˜¯ä¸€ä¸ªå¯æµ‹é‡çš„å‡½æ•°ï¼Œåªå…·æœ‰æœ‰é™çš„ä¸åŒæ•°å€¼
:::

:::{admonition} Satz
Zu jeder $\sigma$-Algebra auf $X$ und jeder meÃŸbaren Funktion $f \colon X \to \mathbb{R}$ gibt es eine Folge von Treppenfunktionen $t_n \colon X \to \mathbb{R}$, die gegen $f$ konvergiert: $t_n \to f$.
:::

Damit lassen sich sehr viele Aussagen beweisen, indem man sie fÃ¼r Treppenfunktionen beweist (so auch die Konstruktion des Lebesgue-Integrals). Man kann daraus auch weitreichende UniversalitÃ¤tsaussagen konstruieren, wenn ein Computermodell in der Lage ist, Treppenfunktionen beliebig genau zu approximieren. Damit lÃ¤sst sich auch die UniversalitÃ¤t von neuronalen Netzen einsehen.

```
æœ‰äº†è¿™ä¸ªï¼Œéå¸¸å¤šçš„è¯­å¥å¯ä»¥é€šè¿‡è¯æ˜æ¥¼æ¢¯å‡½æ•°æ¥è¯æ˜ï¼ˆæ¯”å¦‚è¯´å‹’è´æ–¯æ ¼ç§¯åˆ†çš„æ„é€ ï¼‰ã€‚å¦‚æœä¸€ä¸ªè®¡ç®—æœºæ¨¡å‹èƒ½å¤Ÿä»¥ä»»æ„çš„ç²¾åº¦è¿‘ä¼¼æ¢¯å½¢å‡½æ•°ï¼Œäººä»¬è¿˜å¯ä»¥ä»ä¸­æ„å»ºå‡ºæ„ä¹‰æ·±è¿œçš„æ™®éæ€§å£°æ˜ã€‚è¿™ä¹Ÿè®©æˆ‘ä»¬çœ‹åˆ°äº†ç¥ç»ç½‘ç»œçš„æ™®éæ€§ã€‚

```

Zuletzt soll nicht unerwÃ¤hnt bleiben, dass es einen berechtigten Einwand gegenÃ¼ber diesem Formalismus gibt: am Rechner lÃ¤sst sich nur konstruktive Mathematik implementieren, der Satz vom ausgeschlossenen Dritten und das Auswahlaxiom sind nicht implementierbar. In dieser Logik aber (der konstruktivistischen / sogenannten intuitionistischen) lassen sich fÃ¼r einen metrischen Raum $X$ alle Mengen als meÃŸbar bezeichnen, weil die nicht-meÃŸbaren Teilmengen eben nicht konstruierbar sind. Damit wird manches einfacher, aber eben auch vieles unmÃ¶glich. Wir begnÃ¼gen uns nun als damit, dass wir wissen, wie sich Texte lesen lassen, die den Ã¼blichen Formalismus verwenden, und auÃŸerdem eine gute Ausrede zur Hand haben, warum wir uns mit dem Formalismus nicht lÃ¤nger auseinander setzen werden.

```
æœ€åï¼Œä¸åº”è¯¥ä¸æçš„æ˜¯ï¼Œå¯¹è¿™ç§å½¢å¼ä¸»ä¹‰æœ‰ä¸€ä¸ªåˆç†çš„åå¯¹æ„è§ï¼šåªæœ‰æ„é€ æ•°å­¦å¯ä»¥åœ¨è®¡ç®—æœºä¸Šå®ç°ï¼Œæ’é™¤ç¬¬ä¸‰å®šç†å’Œé€‰æ‹©å…¬ç†ä¸èƒ½å®ç°ã€‚ç„¶è€Œï¼Œåœ¨è¿™ç§é€»è¾‘ä¸­ï¼ˆå»ºæ„ä¸»ä¹‰/æ‰€è°“çš„ç›´è§‰ä¸»ä¹‰é€»è¾‘ï¼‰ï¼Œä¸€ä¸ªå…¬åˆ¶ç©ºé—´ğ‘‹çš„æ‰€æœ‰é›†åˆéƒ½å¯ä»¥è¢«æè¿°ä¸ºå¯æµ‹é‡çš„ï¼Œå› ä¸ºéå¯æµ‹é‡çš„å­é›†æ˜¯ä¸å¯å»ºæ„çš„ã€‚è¿™ä½¿ä¸€äº›äº‹æƒ…æ›´å®¹æ˜“ï¼Œä½†ä¹Ÿä½¿è®¸å¤šäº‹æƒ…ä¸å¯èƒ½ã€‚
```
Wenn Sie sich gern im weiteren Verlauf der Vorlesung mit interaktiven Spielchen der Stochastik nÃ¤hern wollen, ist [Random Services](
https://randomservices.org/random/prob/index.html) genau das Richtige fÃ¼r Sie.
Wenn Sie es lieber elegant-visuell mÃ¶gen, wird [Seeing Theory](https://seeing-theory.brown.edu/) Sie durch den Stochastik-Teil der Vorlesung begleiten.

```
æˆ‘ä»¬ç°åœ¨æ»¡è¶³äºçŸ¥é“å¦‚ä½•é˜…è¯»ä½¿ç”¨é€šå¸¸çš„å½¢å¼ä¸»ä¹‰çš„æ–‡æœ¬ï¼ŒåŒæ—¶ä¹Ÿæœ‰ä¸€ä¸ªå¾ˆå¥½çš„å€Ÿå£åœ¨æ‰‹ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆæˆ‘ä»¬å°†ä¸å†å¤„ç†å½¢å¼ä¸»ä¹‰ã€‚
å¦‚æœä½ å–œæ¬¢éšç€è®²åº§çš„è¿›è¡Œç”¨äº’åŠ¨æ¸¸æˆæ¥æ¥è¿‘éšæœºæ€§ï¼Œé‚£ä¹ˆéšæœºæœåŠ¡æ˜¯ä¸ºä½ å‡†å¤‡çš„ã€‚å¦‚æœä½ å–œæ¬¢ä¼˜é›…çš„è§†è§‰æ–¹æ³•ï¼Œã€Šçœ‹è§ç†è®ºã€‹å°†å¼•å¯¼ä½ å®Œæˆè®²åº§çš„éšæœºéƒ¨åˆ†ã€‚
```