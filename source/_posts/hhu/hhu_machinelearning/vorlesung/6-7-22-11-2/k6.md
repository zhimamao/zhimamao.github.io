---
title: machine-learning-vorlseung6-回归
date: 2022-11-2 10:03:45
categories : 
- hhu
- machine-learning
tags:
password: cocovv
---
# machine-learning-voelseung6-回归
[toc]

#### a.机器学习是干啥的
你或许每天都在不知不觉中使用了机器学习的算法每次，你打开谷歌、必应搜索到你需要的内容，正是因为他们有良好的学习算法。谷歌和微软实现了学习算法来排行网页每次，你用Facebook或苹果的图片分类程序他能认出你朋友的照片，这也是机器学习。每次您阅读您的电子邮件垃圾邮件筛选器，可以帮你过滤大量的垃圾邮件这也是一种学习算法。对我来说，我感到激动的原因之一是<font color=red>有一天做出一个和人类一样聪明的机器</font>。实现这个想法任重而道远，许多AI研究者认为，实现这个目标最好的方法是通过让机器试着模仿人的大脑学习我会在这门课中介绍一点这方面的内容

#### b.监督学习
主要的两种类型被我们称之为监督学习和无监督学习。
在这里简单说两句，监督学习这个想法是指，我们将教计算机如何去完成任务，而在无监督学习中，我们打算让它自己进行学习。

## 列子
假如说你想预测房价。
前阵子，一个学生从波特兰俄勒冈州的研究所收集了一些房价的数据。你把这些数据画出来，看起来是这个样子：横轴表示房子的面积，单位是平方英尺，纵轴表示房价，单位是千美元。那基于这组数据，假如你有一个朋友，他有一套750平方英尺房子，现在他希望把房子卖掉，他想知道这房子能卖多少钱。
那么关于这个问题，机器学习算法将会怎么帮助你呢？
![1](./k6/1.%E5%88%97%E5%AD%90.png)

 我们应用学习算法，可以在这组数据中画一条直线，或者换句话说，<font color=red>拟合</font>一条直线，根据这条线我们可以推测出，这套房子可能卖，当然这不是<font color=red>唯一</font>的算法。可能还有更好的，比如我们不用<font color=red>直线</font>拟合这些数据，用<font color=red>二次方程</font>去拟合可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近。稍后我们将讨论<font color=red>如何选择</font>学习算法，如何决定用直线还是二次方程来拟合。两个方案中有一个能让你朋友的房子出售得更<font color=red>合理</font>。以上就是监督学习的例子。

可以看出，监督学习指的就是我们<font color=red>给学习算法一个数据集</font>。这个数据集由“正确答案”组成。在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。用术语来讲，这叫做<font color=red>回归问题</font>。我们试着推测出<font color=Blue>一个连续值的结果，即房子的价格</font>。

# 题
现在来个小测验：假设你经营着一家公司，你想开发学习算法来处理这两个问题：
1.你有一大批同样的货物，想象一下，你有上千件一模一样的货物等待出售，这时你想预测接下来的三个月能卖多少件？
2.你有许多客户，这时你想写一个软件来检验每一个用户的账户。对于每一个账户，你要判断它们是否曾经被盗过？
那这两个问题，它们属于<font color=red>分类问题、还是回归问题</font>?
问题一是一个回归问题，因为你知道，如果我有数千件货物，我会把它看成一个实数，一个连续的值。因此卖出的物品数，也是一个连续的值。
问题二是一个分类问题，因为我会把预测的值，用 0 来表示账户未被盗，用 1 表示账户曾经被盗过。所以我们根据账号是否被盗过，把它们定为0 或 1，然后用算法推测一个账号是 0 还是 1，因为只有少数的离散值，所以我把它归为分类问题。

# 回归问题
![2](./k6/2%E3%80%82%E5%9B%9E%E5%BD%92.png)
面对一个回归问题，我们可简要描述其求解流程：

1. <font color=red>选定训练模型</font>，即我们为程序选定一个求解框架，如线性回归模型(Linear Regression)等。<font color=Blue>（那个函数f...）</font>
2. <font color=red>导入训练集</font> train_set，即给模型提供大量可供学习参考的正确数据。<font color=Blue>上面的x和yz都在里面</font>
3. 选择<font color=red>合适的学习算法</font>，通过训练集中大量输入输出结果让程序不断优化输入数据与输出数据间的关联性，从而提升模型的预测准确度。<font color=Blue>（那个算子）</font>
4. 在训练结束后即可让模型<font color=red>预测结果</font>，我们为程序提供一组新的输入数据，模型根据训练集的学习成果来预测这组输入对应的输出值。
## 1.单变量线性回归(Linear Regression with One Variable)

### a.线性回归算法
线性回归就是要找一条直线，并且让这条直线尽可能地拟合图中的数据点
![3](./k6/4.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.PNG)

### 损失函数
![4](./k6/5.%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.PNG)
![5](./k6/5.%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B02.PNG)
现在我们知道了损失函数是衡量回归模型误差的函数，也就是我们要的“直线”的评价标准。这个函数的值越小，说明直线越能拟合我们的数据

### 最小二乘法
![z1](./k6/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%981.PNG)
![z2](./k6/%E6%9C%80%E5%B0%8F2.PNG)
![z3](./k6/%E6%9C%80%E5%B0%8F3.PNG)
![12](./k6/3.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.PNG)
![13](./k6/13.PNG)
### python
![sunshipython](./k6/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0python.PNG)

## 多元线性回归
![duoyuan](./k6/%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7.PNG)
![duoyuan2](./k6/%E5%A4%9A%E5%85%832.PNG)
![duoyuan3](./k6/%E5%A4%9A%E5%85%833.PNG)
![duoyuan4](./k6/%E5%A4%9A%E5%85%834.PNG)
![duoyuan5](./k6/%E5%A4%9A%E5%85%835.PNG)

##  迈向非线性函数的线性回归
### 多项式回归
![多项式1](./k6/%E5%A4%9A%E9%A1%B9%E5%BC%8F1.PNG)
![多项式2](./k6/%E5%A4%9A%E9%A1%B9%E5%BC%8F2.PNG)
![duoxiangshi1](./k6/%E5%A4%9A%E9%A1%B9%E5%BC%8F3.PNG)

## 岭回归
岭回归(英文名：ridge regression, Tikhonov regularization)是一种专用于共线性数据分析的有偏估计回归方法，实质上是一种改良的最小二乘估计法，通过放弃最小二乘法的无偏性，以损失部分信息、降低精度为代价获得回归系数更为符合实际、更可靠的回归方法，对病态数据的拟合要强于最小二乘法。
## 补充 最小二乘法
![最小](./k6/001%20-%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B9%8B%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95.png)

![岭1](./k6/linghuigui1.PNG)
![岭2](./k6/%E5%B2%AD%E5%9B%9E%E5%BD%922.PNG)

## 贝叶斯线性回归
![]()
![]()


